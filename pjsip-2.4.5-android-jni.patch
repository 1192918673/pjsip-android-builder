diff -Naur pjproject-2.4.5/pjmedia/src/pjmedia-audiodev/android_jni_dev.c pjproject-2.4.5-android-jni/pjmedia/src/pjmedia-audiodev/android_jni_dev.c
--- pjproject-2.4.5/pjmedia/src/pjmedia-audiodev/android_jni_dev.c	2015-08-10 09:11:39.000000000 +0000
+++ pjproject-2.4.5-android-jni/pjmedia/src/pjmedia-audiodev/android_jni_dev.c	2016-03-05 16:21:55.000000000 +0000
@@ -33,6 +33,8 @@
 #if defined(PJMEDIA_AUDIO_DEV_HAS_ANDROID_JNI) && \
     PJMEDIA_AUDIO_DEV_HAS_ANDROID_JNI != 0
 
+#define COMPATIBLE_ALSA 1
+
 #include <jni.h>
 #include <sys/resource.h>
 #include <sys/system_properties.h>
@@ -222,10 +224,23 @@
 {
     struct android_aud_stream *stream = (struct android_aud_stream *)userData;
     jmethodID read_method=0, record_method=0, stop_method=0;
-    int size = stream->rec_buf_size;
+    
+    int bytesRead;
+    int size =  stream->samples_per_frame * stream->bytes_per_sample;
+    int nframes = stream->samples_per_frame / stream->channel_count;
+    
     jbyteArray inputBuffer;
     jbyte *buf;
     JNIEnv *jni_env = 0;
+    pj_timestamp tstamp, now, last_frame;
+    
+    int elapsed_time = 0;
+    //Frame time in ms
+    int frame_time = nframes * 1000 / stream->samples_per_sec;
+    int missed_time = frame_time;
+    int to_wait = 0;
+    tstamp.u64 = 0;
+    
     pj_bool_t attached = attach_jvm(&jni_env);
     
     PJ_ASSERT_RETURN(jni_env, 0);
@@ -233,11 +248,11 @@
     if (!stream->record) {
         goto on_return;
     }
-
+    
     PJ_LOG(5, (THIS_FILE, "Recorder thread started"));
-
+    
     /* Get methods ids */
-    read_method = (*jni_env)->GetMethodID(jni_env, stream->record_class, 
+    read_method = (*jni_env)->GetMethodID(jni_env, stream->record_class,
                                           "read", "([BII)I");
     record_method = (*jni_env)->GetMethodID(jni_env, stream->record_class,
                                             "startRecording", "()V");
@@ -267,9 +282,6 @@
     (*jni_env)->CallVoidMethod(jni_env, stream->record, record_method);
     
     while (!stream->quit_flag) {
-        pjmedia_frame frame;
-        pj_status_t status;
-        int bytesRead;
         
         if (!stream->running) {
             (*jni_env)->CallVoidMethod(jni_env, stream->record, stop_method);
@@ -279,39 +291,66 @@
             (*jni_env)->CallVoidMethod(jni_env, stream->record, record_method);
         }
         
+        // Credits to CSipSimple's android_jni_dev.c for this one
+#if COMPATIBLE_ALSA
+        pj_get_timestamp(&now);
+        // Time between now and last frame next frame (ms)
+        elapsed_time = pj_elapsed_msec(&last_frame, &now);
+        
+        pj_get_timestamp(&last_frame);
+        
+        //Update missed time
+        // Positive if we are late
+        // Negative if we are earlier
+        // dividing by 2 is empiric result
+        // on N1 if not we get buffer overflow I assume that it fill packets faster than the frequency
+        missed_time = (missed_time / 2) + elapsed_time - frame_time;
+        
+        //If we go faster than the buffer filling, we have to wait
+        if (missed_time <= 0) {
+            to_wait = - missed_time - 2;
+            if (to_wait > 0) {
+                //PJ_LOG (4, (THIS_FILE, "Faster than the buffer filling. Wait for %d / %d", to_wait, frame_time));
+                pj_thread_sleep(to_wait);
+            }
+        }
+#endif
+        
         bytesRead = (*jni_env)->CallIntMethod(jni_env, stream->record,
                                               read_method, inputBuffer,
                                               0, size);
         if (bytesRead <= 0 || bytesRead != size) {
             PJ_LOG (4, (THIS_FILE, "Record thread : error %d reading data",
-                                   bytesRead));
+                        bytesRead));
             continue;
         }
-
+        
         buf = (*jni_env)->GetByteArrayElements(jni_env, inputBuffer, 0);
+        pjmedia_frame frame;
         frame.type = PJMEDIA_FRAME_TYPE_AUDIO;
         frame.size =  size;
         frame.bit_info = 0;
         frame.buf = (void *)buf;
-        frame.timestamp.u64 = stream->rec_timestamp.u64;
-
+        frame.timestamp.u64 = tstamp.u64;
+        
+        pj_status_t status;
         status = (*stream->rec_cb)(stream->user_data, &frame);
         (*jni_env)->ReleaseByteArrayElements(jni_env, inputBuffer, buf,
-        				     JNI_ABORT);
-	if (status != PJ_SUCCESS || stream->quit_flag)
-	    break;
-
-        stream->rec_timestamp.u64 += stream->param.samples_per_frame /
-                                     stream->param.channel_count;
+                                             JNI_ABORT);
+        if (status != PJ_SUCCESS || stream->quit_flag)
+            break;
+        
+        //Update for next step
+        tstamp.u64 += nframes;
     }
-
+    
     (*jni_env)->DeleteLocalRef(jni_env, inputBuffer);
     
 on_return:
     detach_jvm(attached);
     PJ_LOG(5, (THIS_FILE, "Recorder thread stopped"));
     stream->rec_thread_exited = 1;
-
+    
     return 0;
 }
 
